{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "40ygIDXEhjav"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import glob2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from random import randrange\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='./log.log',level=10, force=True, format='%(asctime)s   %(funcName)s - %(levelname)s:%(message)s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LXMhyoM3Wnq4"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_cat = r'./PetImages/Cat/**'\n",
    "link_dog = r'./PetImages/Dog/**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "images  = []\n",
    "labels = []\n",
    "list_cat = glob2.glob(link_cat)\n",
    "print(len(list_cat))\n",
    "for i in range(n_samples):\n",
    "    if('jpg' in list_cat[i]):\n",
    "        img = Image.open(list_cat[i]).convert('RGB')\n",
    "        img = img.resize((400,400), Image.LANCZOS)\n",
    "        if len(np.array(img).shape)  == 3:\n",
    "            images.append(np.array(img))\n",
    "            labels.append(1)\n",
    "            \n",
    "list_dog = glob2.glob(link_dog)\n",
    "print(len(list_dog))\n",
    "for i in range(n_samples):\n",
    "    if('jpg' in list_dog[i]):\n",
    "        img = Image.open(list_dog[i]).convert('RGB')\n",
    "        img = img.resize((400,400), Image.LANCZOS)\n",
    "        if len(np.array(img).shape)  == 3:\n",
    "            images.append(np.array(img))\n",
    "            labels.append(-1)\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "for index in range(len(images)):\n",
    "    if images[index].shape[2] != 3:\n",
    "        print(index, images[index].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oGqEcWO3NQs1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x.flatten() for x in X_train])\n",
    "x_test = np.array([x.flatten() for x in X_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1, -1,  1, -1,  1, -1,  1, -1, -1,  1, -1, -1,  1,\n",
       "       -1, -1, -1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1,  1, -1, -1,  1,\n",
       "        1, -1, -1,  1,  1, -1,  1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1,\n",
       "        1, -1, -1,  1, -1,  1,  1, -1,  1,  1, -1, -1, -1,  1,  1, -1, -1,\n",
       "        1,  1, -1,  1,  1, -1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,  1,\n",
       "        1,  1, -1,  1,  1, -1, -1,  1,  1,  1,  1, -1, -1,  1,  1, -1, -1,\n",
       "       -1, -1,  1,  1, -1,  1, -1,  1,  1,  1,  1,  1, -1, -1, -1,  1, -1,\n",
       "       -1,  1,  1, -1, -1, -1, -1,  1, -1,  1,  1, -1, -1,  1, -1,  1, -1,\n",
       "        1,  1, -1, -1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "  def __init__(self, C=1.0, gamma=0.1, tol=1e-3, max_iter=1200):\n",
    "    self.C = C\n",
    "    self.gamma = gamma\n",
    "    self.tol = tol\n",
    "    self.max_iter = max_iter\n",
    "    self.n_iter = 0\n",
    "    self.eps = 1e-3\n",
    "\n",
    "  def rbf(self, x1, x2):\n",
    "    return np.exp(-self.gamma * (np.linalg.norm(x1 - x2) **2 ))\n",
    "  \n",
    "  def get_error(self, i):\n",
    "    return (self.output(i) - self.y[i]) if self.is_bounded(i) else self.errors[i]\n",
    "  \n",
    "  def is_bounded(self, i):\n",
    "    if 0 < self.alphas[i] and self.alphas[i] < self.C:\n",
    "      return False\n",
    "    return True\n",
    "\n",
    "  def find_non_bound_indexes(self):\n",
    "    self.non_bound_indexes = [i for i in range(self.n_samples) if not self.is_bounded(i)]\n",
    "\n",
    "  def output(self, x):\n",
    "    s = -self.b\n",
    "    for alpha, sv_y, sv_x in zip(self.alphas, self.y, self.X):\n",
    "      s += alpha * sv_y * self.rbf(sv_x, x)\n",
    "    return s\n",
    "  \n",
    "  def predict(self, X):\n",
    "    pred = []\n",
    "    for x in X:\n",
    "      pred.append(np.sign(self.output(x)))\n",
    "    return pred\n",
    "    \n",
    "  def compute_L_H(self):\n",
    "    if self.y1 != self.y2:\n",
    "      L = max(0, self.alpha2 - self.alpha1)\n",
    "      H = min(self.C, self.C + self.alpha2 - self.alpha1)\n",
    "    else:\n",
    "      L = max(0, self.alpha2 + self.alpha1 - self.C)\n",
    "      H = min(self.C, self.alpha2 + self.alpha1)\n",
    "    return L, H\n",
    "  \n",
    "  def compute_threshold(self, alpha1_new, alpha2_new, k11, k12, k22):\n",
    "    b1 = self.E1 + self.y1 * (alpha1_new - self.alpha1) * k11 + \\\n",
    "        self.y2 * (alpha2_new - self.alpha2) * k12 + self.b\n",
    "    b2 = self.E2 + self.y1 * (alpha1_new - self.alpha1) * k12 + \\\n",
    "        self.y2 * (alpha2_new - self.alpha2) * k22 + self.b\n",
    "\n",
    "    if 0 < alpha1_new and alpha1_new < self.C:\n",
    "      new_b = b1\n",
    "    elif 0 < alpha2_new and alpha2_new < self.C:\n",
    "      new_b = b2\n",
    "    else:\n",
    "      new_b = (b1+b2)/2.0\n",
    "    return new_b\n",
    "    \n",
    "  def update_error_cache(self, alpha1_new, alpha2_new, i1, i2, old_b):\n",
    "    delta1 = self.y1 * (alpha1_new - self.alpha1)\n",
    "    delta2 = self.y2 * (alpha2_new - self.alpha2)\n",
    "    \n",
    "    for i in range(self.n_samples):\n",
    "      if not self.is_bounded(i):\n",
    "        self.errors[i] += delta1 * self.rbf(self.x1, self.X[i]) + \\\n",
    "                          delta2 * self.rbf(self.x2, self.X[i]) + \\\n",
    "                          self.b - old_b\n",
    "    if not self.is_bounded(i1):\n",
    "      self.errors[i1] = 0\n",
    "    if not self.is_bounded(i2):\n",
    "      self.errors[i2] = 0\n",
    "    \n",
    "  def get_alpha2(self, L, H, k11, k12, k22, s):\n",
    "    eta = k11 + k22 - 2 * k12\n",
    "    if eta > 0:\n",
    "      alpha2_new = self.alpha2 + self.y2 * (self.E1-self.E2)/eta\n",
    "      alpha2_new = min(H, max(L, alpha2_new))\n",
    "    else:\n",
    "      logging.warn(\"ETA <= 0\")\n",
    "      f1 = self.y1*(self.E1 + self.b) - self.alpha1*k11 - s*self.alpha2*k12\n",
    "      f2 = self.y2*(self.E2 + self.b) - s*self.alpha1*k12 - self.alpha2*k22\n",
    "      L1 = self.alpha1 + s*(self.alpha2-L)\n",
    "      H1 = self.alpha1 + s*(self.alpha2-H)\n",
    "      Lobj = L1*f1 + L*f2 + 0.5*(L1**2)*k11 + 0.5*(L**2)*k22 + s*L*L1*k12\n",
    "      Hobj = H1*f1 + H*f2 + 0.5*(H1**2)*k11 + 0.5*(H**2)*k22 + s*H*H1*k12\n",
    "      if Lobj < Hobj - self.eps:\n",
    "        alpha2_new = L\n",
    "      elif Lobj > Hobj + self.eps:\n",
    "        alpha2_new = H\n",
    "      else:\n",
    "        alpha2_new = self.alpha2\n",
    "    return alpha2_new\n",
    "    \n",
    "  def take_step(self, i1, i2):\n",
    "    if i1 == i2:\n",
    "      logging.debug(\"i1 = i2, exit\")\n",
    "      return 0\n",
    "    self.y1 = self.y[i1]\n",
    "    self.alpha1 = self.alphas[i1]\n",
    "    self.x1 = self.X[i1]\n",
    "    self.E1 = self.get_error(i1)\n",
    "    \n",
    "    s = self.y1 * self.y2\n",
    "    L, H = self.compute_L_H()\n",
    "    if L==H:\n",
    "      return 0\n",
    "    k11 = self.rbf(self.x1, self.x1)\n",
    "    k12 = self.rbf(self.x1, self.x2)\n",
    "    k22 = self.rbf(self.x2, self.x2)\n",
    "    alpha2_new = self.get_alpha2(L, H, k11, k12, k22, s)\n",
    "    if abs(alpha2_new - self.alpha2) < self.tol * (alpha2_new + self.alpha2 + self.eps):\n",
    "      return 0\n",
    "    alpha1_new = self.alpha1 + s * (self.alpha2 - alpha2_new)\n",
    "    old_b = self.b\n",
    "    self.b = self.compute_threshold(alpha1_new, alpha2_new, k11, k12, k22)\n",
    "    self.update_error_cache(alpha1_new, alpha2_new, i1, i2, old_b)\n",
    "    self.alphas[i1] = alpha1_new\n",
    "    self.alphas[i2] = alpha2_new\n",
    "    logging.warn(f\"Done {i1} and {i2}\")\n",
    "    return 1\n",
    "  \n",
    "  def second_choice_heuristic(self, i2):\n",
    "    i1 = -1\n",
    "    max = 0\n",
    "    for j in self.non_bound_indexes:\n",
    "      step = abs(self.get_error(j) - self.errors[i2])\n",
    "      if step > max:\n",
    "        max = step\n",
    "        i1 = j\n",
    "    return i1\n",
    "\n",
    "  def examine_example(self, i2):\n",
    "    self.y2 = self.y[i2]\n",
    "    self.alpha2 = self.alphas[i2]\n",
    "    self.x2 = self.X[i2]\n",
    "    self.E2 = self.get_error(i2)\n",
    "    r2 = self.E2 * self.y2\n",
    "    if ((r2 < -self.tol and self.alpha2 < self.C) or \\\n",
    "      (r2 > self.tol and self.alpha2 > 0)):      \n",
    "      self.find_non_bound_indexes()\n",
    "      logging.info(f\"Found {len(self.non_bound_indexes)} non bound\")\n",
    "      if (len(self.non_bound_indexes) > 1):\n",
    "        logging.info(\"Starting branch 1\")\n",
    "        i1 = self.second_choice_heuristic(i2)\n",
    "        logging.info(f\"Take step {i1} and {i2}\")\n",
    "        if i1 >= 0 and self.take_step(i1, i2):\n",
    "          return 1\n",
    "      logging.info(\"Starting branch 2\")\n",
    "      if len(self.non_bound_indexes) > 0:\n",
    "        rand_i = randrange(len(self.non_bound_indexes))\n",
    "        for i1 in self.non_bound_indexes[rand_i:] + self.non_bound_indexes[:rand_i]:\n",
    "          logging.info(f\"Take step {i1} and {i2}\")\n",
    "          if self.take_step(i1, i2):\n",
    "            return 1\n",
    "      logging.info(\"Starting branch 3\")\n",
    "      rand_i = randrange(self.n_samples)\n",
    "      all_indexes = list(range(self.n_samples))\n",
    "      for i1 in all_indexes[rand_i:] + all_indexes[:rand_i]:\n",
    "        logging.info(f\"Take step {i1} and {i2}\")\n",
    "        if self.take_step(i1, i2):\n",
    "          return 1\n",
    "    return 0\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    random.seed(0)\n",
    "    logging.info(\"Setting startup parameters\")\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "    self.n_samples, self.n_features = X.shape\n",
    "    self.errors = np.zeros(self.n_samples)\n",
    "    self.alphas = np.zeros(self.n_samples)\n",
    "    self.b = 0\n",
    "    num_changed = 0\n",
    "    examine_all = True\n",
    "    logging.info(\"Start while loop\")\n",
    "    self.n_iter = 0\n",
    "    while (num_changed > 0) or examine_all:\n",
    "      self.n_iter += 1\n",
    "      logging.info(f\"N iter: {self.n_iter}\")\n",
    "      num_changed = 0\n",
    "      if examine_all:\n",
    "        logging.info(\"for loop 1\")\n",
    "        for i in range(self.n_samples):\n",
    "          num_changed += self.examine_example(i)\n",
    "      else:\n",
    "        logging.info(\"for loop 2\")\n",
    "        for i in range(self.n_samples):\n",
    "          if not self.is_bounded(i):\n",
    "            num_changed += self.examine_example(i)\n",
    "      logging.info(f\"examine_all: {examine_all}, numchanged: {num_changed}\")\n",
    "      if examine_all:\n",
    "        examine_all = False\n",
    "      elif num_changed == 0:\n",
    "        examine_all = True\n",
    "        \n",
    "    sv_idx = (self.alphas > 0)\n",
    "    logging.info(f\"Filtering support vectors, there are {np.count_nonzero(sv_idx)} alphas\")\n",
    "    self.support_vectors = X[sv_idx]\n",
    "    self.support_vector_labels = y[sv_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPX7eu3l_--N",
    "outputId": "5c4d5586-0b7f-4f40-b357-58e80195bdfd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69911/3174018114.py:119: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
      "  logging.warn(f\"Done {i1} and {i2}\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m svm \u001b[39m=\u001b[39m SVM(gamma \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mx_train\u001b[39m.\u001b[39mvar()))\n\u001b[0;32m----> 2\u001b[0m svm\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m      3\u001b[0m pred \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m      4\u001b[0m accuracy_score(pred, y_test)\n",
      "Cell \u001b[0;32mIn[12], line 189\u001b[0m, in \u001b[0;36mSVM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples):\n\u001b[1;32m    188\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_bounded(i):\n\u001b[0;32m--> 189\u001b[0m       num_changed \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexamine_example(i)\n\u001b[1;32m    190\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexamine_all: \u001b[39m\u001b[39m{\u001b[39;00mexamine_all\u001b[39m}\u001b[39;00m\u001b[39m, numchanged: \u001b[39m\u001b[39m{\u001b[39;00mnum_changed\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m examine_all:\n",
      "Cell \u001b[0;32mIn[12], line 160\u001b[0m, in \u001b[0;36mSVM.examine_example\u001b[0;34m(self, i2)\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[39mfor\u001b[39;00m i1 \u001b[39min\u001b[39;00m all_indexes[rand_i:] \u001b[39m+\u001b[39m all_indexes[:rand_i]:\n\u001b[1;32m    159\u001b[0m     logging\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTake step \u001b[39m\u001b[39m{\u001b[39;00mi1\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mi2\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 160\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake_step(i1, i2):\n\u001b[1;32m    161\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 101\u001b[0m, in \u001b[0;36mSVM.take_step\u001b[0;34m(self, i1, i2)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas[i1]\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX[i1]\n\u001b[0;32m--> 101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mE1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_error(i1)\n\u001b[1;32m    103\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my1 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my2\n\u001b[1;32m    104\u001b[0m L, H \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_L_H()\n",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m, in \u001b[0;36mSVM.get_error\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_error\u001b[39m(\u001b[39mself\u001b[39m, i):\n\u001b[0;32m---> 14\u001b[0m   \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(i) \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my[i]) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_bounded(i) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors[i]\n",
      "Cell \u001b[0;32mIn[12], line 27\u001b[0m, in \u001b[0;36mSVM.output\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m s \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n\u001b[1;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m alpha, sv_y, sv_x \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX):\n\u001b[0;32m---> 27\u001b[0m   s \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m sv_y \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrbf(sv_x, x)\n\u001b[1;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m s\n",
      "Cell \u001b[0;32mIn[12], line 11\u001b[0m, in \u001b[0;36mSVM.rbf\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrbf\u001b[39m(\u001b[39mself\u001b[39m, x1, x2):\n\u001b[0;32m---> 11\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m (np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(x1 \u001b[39m-\u001b[39;49m x2) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m ))\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.10/site-packages/numpy/linalg/linalg.py:2511\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2509\u001b[0m     sqnorm \u001b[39m=\u001b[39m x_real\u001b[39m.\u001b[39mdot(x_real) \u001b[39m+\u001b[39m x_imag\u001b[39m.\u001b[39mdot(x_imag)\n\u001b[1;32m   2510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2511\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(x)\n\u001b[1;32m   2512\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2513\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = SVM(gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lF7j1JviBPZ_"
   },
   "outputs": [],
   "source": [
    "y_train_sklearn = np.array([str(y) for y in y_train])\n",
    "y_test_sklearn = np.array([str(y) for y in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpmSnc60Aa8F",
    "outputId": "9f9be904-2184-40d2-9baf-a4b84dcb399b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6166666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svc.fit(x_train, y_train_sklearn)\n",
    "pred = svc.predict(x_test)\n",
    "accuracy_score(pred, y_test_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.84618477, -1.        , -1.        , -1.        ,\n",
       "        -0.48525263, -0.88835903, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.67630197, -0.91638137, -1.        , -1.        ,\n",
       "        -0.92151731, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.96725608, -0.90533996, -0.66546383, -1.        , -1.        ,\n",
       "        -0.80156863, -1.        , -1.        , -1.        , -0.84111311,\n",
       "        -1.        , -1.        , -1.        , -1.        , -0.19542954,\n",
       "        -1.        , -1.        , -1.        , -0.56715469, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.66465594, -0.8423303 ,\n",
       "        -1.        , -1.        , -0.38911849, -0.71641567, -0.92482623,\n",
       "        -0.93938708, -1.        , -1.        , -0.65894374, -1.        ,\n",
       "        -1.        , -1.        , -0.82435754, -1.        , -1.        ,\n",
       "        -0.03750627, -1.        , -0.6678171 , -0.60209135, -0.66211985,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.78817148,  1.        ,  0.595249  ,  1.        ,  0.56231375,\n",
       "         1.        ,  1.        ,  1.        ,  0.95446996,  1.        ,\n",
       "         1.        ,  0.9690475 ,  0.79531166,  1.        ,  0.67699844,\n",
       "         0.97019349,  1.        ,  0.63107706,  1.        ,  1.        ,\n",
       "         1.        ,  0.80657856,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.75369009,  1.        ,  0.33868419,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.61730302,  0.41403797,\n",
       "         0.66380742,  0.8646384 ,  1.        ,  1.        ,  0.90718199,\n",
       "         1.        ,  1.        ,  0.51012362,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.83865425,  1.        ,  1.        ,  1.        ,\n",
       "         0.76610267,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.75960095,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.dual_coef_"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
