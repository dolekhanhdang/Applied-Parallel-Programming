{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "40ygIDXEhjav"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import glob2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from random import randrange\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='./log.log',level=10, filemode = 'w', force=True, format='%(asctime)s   %(funcName)s - %(levelname)s:%(message)s')"

   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LXMhyoM3Wnq4"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_cat = r'./PetImages/Cat/**'\n",
    "link_dog = r'./PetImages/Dog/**'"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 81,

   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [

    "n_samples = 200\n",

    "images  = []\n",
    "labels = []\n",
    "list_cat = glob2.glob(link_cat)\n",
    "print(len(list_cat))\n",
    "for i in range(n_samples):\n",
    "    if('jpg' in list_cat[i]):\n",
    "        img = Image.open(list_cat[i]).convert('RGB')\n",
    "        img = img.resize((400,400), Image.LANCZOS)\n",
    "        if len(np.array(img).shape)  == 3:\n",
    "            images.append(np.array(img))\n",
    "            labels.append(1)\n",
    "            \n",
    "list_dog = glob2.glob(link_dog)\n",
    "print(len(list_dog))\n",
    "for i in range(n_samples):\n",
    "    if('jpg' in list_dog[i]):\n",
    "        img = Image.open(list_dog[i]).convert('RGB')\n",
    "        img = img.resize((400,400), Image.LANCZOS)\n",
    "        if len(np.array(img).shape)  == 3:\n",
    "            images.append(np.array(img))\n",
    "            labels.append(-1)\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "for index in range(len(images)):\n",
    "    if images[index].shape[2] != 3:\n",
    "        print(index, images[index].shape[2])"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 82,

   "metadata": {
    "id": "oGqEcWO3NQs1"
   },
   "outputs": [],
   "source": [

    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 83,

   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x.flatten() for x in X_train])\n",
    "x_test = np.array([x.flatten() for x in X_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 84,

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "array([-1,  1, -1, -1,  1,  1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1,  1,\n",
       "       -1, -1, -1,  1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1, -1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1,  1,  1, -1, -1,  1,  1, -1,  1, -1,  1,  1,\n",
       "        1,  1, -1,  1,  1, -1,  1,  1,  1, -1, -1, -1, -1,  1, -1, -1, -1,\n",
       "        1,  1, -1, -1,  1, -1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,\n",
       "       -1, -1, -1,  1, -1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1,  1,  1, -1, -1, -1,  1,  1,  1,  1,  1, -1,  1, -1,\n",
       "       -1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1,\n",
       "        1, -1, -1, -1, -1, -1, -1, -1,  1,  1, -1,  1,  1, -1,  1,  1, -1,\n",
       "       -1,  1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1,  1, -1, -1, -1,  1,\n",
       "       -1, -1,  1,  1,  1, -1,  1, -1, -1,  1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1, -1, -1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1,\n",
       "       -1,  1, -1,  1, -1,  1,  1,  1, -1,  1,  1, -1,  1,  1,  1, -1,  1,\n",
       "       -1,  1,  1, -1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1, -1, -1, -1,\n",
       "        1,  1, -1,  1, -1, -1,  1,  1,  1, -1, -1, -1, -1,  1,  1,  1,  1,\n",
       "       -1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1,  1,  1, -1,  1,  1, -1,\n",
       "       -1,  1, -1, -1, -1,  1,  1,  1])"
      ]
     },
     "execution_count": 84,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 85,

   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "  def __init__(self, C=1.0, gamma=0.1, tol=1e-3, max_iter=1200):\n",
    "    self.C = C\n",
    "    self.gamma = gamma\n",
    "    self.tol = tol\n",
    "    self.max_iter = max_iter\n",
    "    self.n_iter = 0\n",

    "    self.eps = 1e-5\n",

    "\n",
    "  def rbf(self, x1, x2):\n",
    "    return np.exp(-self.gamma * (np.linalg.norm(x1 - x2) **2 ))\n",
    "  \n",

    "  def output(self, x):\n",
    "    return np.sum([self.alphas[i] * self.y[i] * self.rbf(self.X[i], x) for i in range(self.n_samples)]) - self.b\n",
    "\n",
    "  def get_error(self, i):\n",
    "    if self.non_bound[i]:\n",
    "      return self.errors[i]\n",
    "    else:\n",
    "      op = self.output(self.X[i]) - self.y[i]\n",
    "      self.errors[i] = op\n",
    "      return op  \n",
    "\n",

    "  def predict(self, X):\n",
    "    pred = []\n",
    "    for x in X:\n",
    "      pred.append(np.sign(self.output(x)))\n",
    "    return pred\n",
    "    \n",
    "  def compute_L_H(self):\n",
    "    if self.y1 != self.y2:\n",
    "      L = max(0, self.alpha2 - self.alpha1)\n",
    "      H = min(self.C, self.C + self.alpha2 - self.alpha1)\n",
    "    else:\n",
    "      L = max(0, self.alpha2 + self.alpha1 - self.C)\n",
    "      H = min(self.C, self.alpha2 + self.alpha1)\n",
    "    return L, H\n",
    "  \n",
    "  def compute_threshold(self, alpha1_new, alpha2_new, k11, k12, k22):\n",
    "    b1 = self.E1 + self.y1 * (alpha1_new - self.alpha1) * k11 + \\\n",
    "        self.y2 * (alpha2_new - self.alpha2) * k12 + self.b\n",
    "    b2 = self.E2 + self.y1 * (alpha1_new - self.alpha1) * k12 + \\\n",
    "        self.y2 * (alpha2_new - self.alpha2) * k22 + self.b\n",
    "\n",
    "    if 0 < alpha1_new and alpha1_new < self.C:\n",

    "      return b1\n",
    "    if 0 < alpha2_new and alpha2_new < self.C:\n",
    "      return b2\n",
    "    return (b1 + b2)/2.0\n",

    "    \n",
    "  def update_error_cache(self, alpha1_new, alpha2_new, i1, i2, old_b):\n",
    "    delta1 = self.y1 * (alpha1_new - self.alpha1)\n",
    "    delta2 = self.y2 * (alpha2_new - self.alpha2)\n",

    "    # old1 = self.errors[i1]\n",
    "    # old2 = self.errors[i2]\n",
    "    # non_bound_indexes = self.non_bound_idx()\n",
    "    # logging.info(non_bound_indexes)\n",
    "    for i in self.non_bound_idx:\n",
    "      self.errors[i] += delta1 * self.rbf(self.x1, self.X[i]) + \\\n",
    "                        delta2 * self.rbf(self.x2, self.X[i]) + \\\n",
    "                        old_b - self.b\n",
    "    # new1 = self.errors[i1]\n",
    "    # new2 = self.errors[i2]\n",
    "    # true1 = self.output(self.x1) - self.y1\n",
    "    # true2 = self.output(self.x2) - self.y2\n",
    "    # logging.info(f\"{i1}: old:{old1},\\tnew:{new1},\\ttrue:{true1}\")\n",
    "    # logging.info(f\"{i2}: old:{old2},\\tnew:{new2},\\ttrue:{true2}\")\n",
    "\n",
    "    \n",
    "  def update_non_bound(self, i1, i2):\n",
    "    if 0 < self.alphas[i1] and self.alphas[i1] < self.C:\n",
    "      self.non_bound[i1] = True\n",
    "      if i1 not in self.non_bound_idx:\n",
    "        self.non_bound_idx.append(i1)\n",
    "    else:\n",
    "      self.non_bound[i1] = False\n",
    "      if i1 in self.non_bound_idx:\n",
    "        self.non_bound_idx.remove(i1)\n",
    "      \n",
    "    if 0 < self.alphas[i2] and self.alphas[i2] < self.C:\n",
    "      self.non_bound[i2] = True\n",
    "      if i2 not in self.non_bound_idx:\n",
    "        self.non_bound_idx.append(i2)\n",
    "    else:\n",
    "      self.non_bound[i2] = False\n",
    "      if i2 in self.non_bound_idx:\n",
    "        self.non_bound_idx.remove(i2)\n",
    "\n",
    "  # def non_bound_idx(self):\n",
    "  #   return list(np.array(range(self.n_samples))[self.non_bound])\n",
    "    \n",

    "    \n",
    "  def get_alpha2(self, L, H, k11, k12, k22, s):\n",
    "    eta = k11 + k22 - 2 * k12\n",
    "    if eta > 0:\n",
    "      alpha2_new = self.alpha2 + self.y2 * (self.E1-self.E2)/eta\n",
    "      alpha2_new = min(H, max(L, alpha2_new))\n",
    "    else:\n",

    "      print(\"ETA < 0\")\n",
    "      logging.error(\"ETA <= 0\")\n",

    "      f1 = self.y1*(self.E1 + self.b) - self.alpha1*k11 - s*self.alpha2*k12\n",
    "      f2 = self.y2*(self.E2 + self.b) - s*self.alpha1*k12 - self.alpha2*k22\n",
    "      L1 = self.alpha1 + s*(self.alpha2-L)\n",
    "      H1 = self.alpha1 + s*(self.alpha2-H)\n",
    "      Lobj = L1*f1 + L*f2 + 0.5*(L1**2)*k11 + 0.5*(L**2)*k22 + s*L*L1*k12\n",
    "      Hobj = H1*f1 + H*f2 + 0.5*(H1**2)*k11 + 0.5*(H**2)*k22 + s*H*H1*k12\n",
    "      if Lobj < Hobj - self.eps:\n",
    "        alpha2_new = L\n",
    "      elif Lobj > Hobj + self.eps:\n",
    "        alpha2_new = H\n",
    "      else:\n",
    "        alpha2_new = self.alpha2\n",
    "    return alpha2_new\n",
    "    \n",
    "  def take_step(self, i1, i2):\n",
    "    if i1 == i2:\n",

    "      return 0\n",
    "    self.y2 = self.y[i2]\n",
    "    self.alpha2 = self.alphas[i2]\n",
    "    self.x2 = self.X[i2]\n",
    "    self.E2 = self.get_error(i2)\n",
    "    # e2 = self.output(self.x2) - self.y2\n",
    "    # if abs(e2 - self.E2) > 0.00001:\n",
    "    #   logging.info(f\"E[{i2}]: {abs(e2-self.E2)}\")\n",
    "    # self.E2 = e2\n",

    "    s = self.y1 * self.y2\n",
    "    L, H = self.compute_L_H()\n",
    "    if L==H:\n",
    "      return 0\n",
    "    k11 = self.rbf(self.x1, self.x1)\n",
    "    k12 = self.rbf(self.x1, self.x2)\n",
    "    k22 = self.rbf(self.x2, self.x2)\n",

    "    self.alphas[i2] = self.get_alpha2(L, H, k11, k12, k22, s)\n",
    "    if abs(self.alphas[i2] - self.alpha2) < self.eps: # * (alpha2_new + self.alpha2 + self.eps):\n",
    "      return 0\n",
    "    self.alphas[i1] = self.alpha1 + s * (self.alpha2 - self.alphas[i2])\n",
    "    old_b = self.b\n",
    "    self.b = self.compute_threshold(self.alphas[i1], self.alphas[i2], k11, k12, k22)\n",
    "    self.update_non_bound(i1, i2)\n",
    "    self.update_error_cache(self.alphas[i1], self.alphas[i2], i1, i2, old_b)\n",
    "    # self.alphas[i1] = self.alphas[i1]\n",
    "    # self.alphas[i2] = self.alphas[i2]\n",
    "    logging.warning(f\"alpha[{i1}]: {self.alphas[i1]};\\talpha[{i2}]: {self.alphas[i2]}\") #;\\t[{L},  {H}]\")\n",
    "    return 1\n",
    "  \n",
    "  def second_choice_heuristic(self):\n",
    "    i2 = -1\n",
    "    m = 0\n",
    "    for i in self.non_bound_idx:\n",
    "      step = abs(self.get_error(i) - self.E1)\n",
    "      if step > m:\n",
    "        m = step\n",
    "        i2 = i\n",
    "    return i2\n",
    "\n",
    "  def examine_example(self, i1):\n",
    "    self.y1 = self.y[i1]\n",
    "    self.alpha1 = self.alphas[i1]\n",
    "    self.x1 = self.X[i1]\n",
    "    self.E1 = self.get_error(i1)\n",
    "    # e1 = self.output(self.x1) - self.y1\n",
    "    # if abs(e1 - self.E1) > 0.00001:\n",
    "    #   logging.info(f\"E[{i1}]: {abs(e1-self.E1)}\")\n",
    "    # self.E1 = e1\n",
    "    r2 = self.E1 * self.y1\n",
    "    if (r2 < -self.tol and self.alpha1 < self.C) or \\\n",
    "      (r2 > self.tol and self.alpha1 > 0):\n",
    "      # non_bound_indexes = self.non_bound_idx()\n",
    "      n_non_bound = len(self.non_bound_idx)\n",
    "      # n_non_bound = len(non_bound_indexes)\n",
    "      # logging.info(f\"Found {n_non_bound} non bound\")\n",
    "      if (n_non_bound > 1):\n",
    "        # logging.info(\"Branch 1\")\n",
    "        i2 = self.second_choice_heuristic()\n",
    "        if i2 != -1:\n",
    "          # logging.info(f\"Take step {i1} and {i2}\")\n",
    "          if self.take_step(i1, i2):\n",
    "            return 1\n",
    "        \n",
    "      if n_non_bound > 0:\n",
    "        # logging.info(\"Branch 2\")\n",
    "        rand_i = randrange(n_non_bound)\n",
    "        for i2 in self.non_bound_idx[rand_i:] + self.non_bound_idx[:rand_i]:\n",
    "          # logging.info(f\"Take step {i1} and {i2}\")\n",
    "          if self.take_step(i1, i2):\n",
    "            return 1\n",
    "          \n",
    "      # logging.info(\"Branch 3\")\n",
    "      rand_i = randrange(self.n_samples)\n",
    "      all_indexes = list(range(self.n_samples))\n",
    "      for i2 in all_indexes[rand_i:] + all_indexes[:rand_i]:\n",
    "        # logging.info(f\"Take step {i1} and {i2}\")\n",

    "        if self.take_step(i1, i2):\n",
    "          return 1\n",
    "    return 0\n",
    "\n",
    "  def fit(self, X, y):\n",

    "    # random.seed(42)\n",

    "    self.X = X\n",
    "    self.y = y\n",
    "    self.n_samples, self.n_features = X.shape\n",
    "    self.errors = np.zeros(self.n_samples)\n",
    "    self.alphas = np.zeros(self.n_samples)\n",

    "    self.non_bound = np.array([False for _ in range(self.n_samples)])\n",
    "    self.non_bound_idx = []\n",
    "    self.b = 0\n",
    "    num_changed = 0\n",
    "    examine_all = True\n",
    "    self.n_iter = 0\n",
    "    while num_changed > 0 or examine_all:\n",
    "      self.n_iter += 1\n",
    "      logging.debug(f\"N iter: {self.n_iter}\")\n",
    "      logging.debug(f\"examine_all: {examine_all}, numchanged: {num_changed}\")\n",
    "      num_changed = 0\n",
    "      if examine_all:\n",
    "        for i in range(self.n_samples):\n",
    "          num_changed += self.examine_example(i)\n",
    "      else:\n",
    "        for i in range(self.n_samples):\n",
    "          if 0 < self.alphas[i] < self.C:\n",
    "            num_changed += self.examine_example(i)\n",
    "  \n",

    "      if examine_all:\n",
    "        examine_all = False\n",
    "      elif num_changed == 0:\n",
    "        examine_all = True\n",
    "        \n",
    "    sv_idx = (self.alphas > 0)\n",
    "    logging.info(f\"Filtering support vectors, there are {np.count_nonzero(sv_idx)} alphas\")\n",

    "    self.X = X[sv_idx]\n",
    "    self.y = y[sv_idx]\n",
    "    self.n_samples = np.count_nonzero(sv_idx)\n",
    "    logging.info(\"Done fitting\")"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": 86,

   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPX7eu3l_--N",
    "outputId": "5c4d5586-0b7f-4f40-b357-58e80195bdfd"
   },
   "outputs": [
    {

     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",

      "Cell \u001b[0;32mIn[86], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m svm \u001b[39m=\u001b[39m SVM(gamma \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m(x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39mx_train\u001b[39m.\u001b[39mvar()))\n\u001b[0;32m----> 2\u001b[0m svm\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[1;32m      3\u001b[0m pred \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m      4\u001b[0m accuracy_score(pred, y_test)\n",
      "Cell \u001b[0;32mIn[85], line 221\u001b[0m, in \u001b[0;36mSVM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    219\u001b[0m   \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples):\n\u001b[1;32m    220\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas[i] \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC:\n\u001b[0;32m--> 221\u001b[0m       num_changed \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexamine_example(i)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m examine_all:\n\u001b[1;32m    224\u001b[0m   examine_all \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[85], line 185\u001b[0m, in \u001b[0;36mSVM.examine_example\u001b[0;34m(self, i1)\u001b[0m\n\u001b[1;32m    182\u001b[0m   rand_i \u001b[39m=\u001b[39m randrange(n_non_bound)\n\u001b[1;32m    183\u001b[0m   \u001b[39mfor\u001b[39;00m i2 \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_bound_idx[rand_i:] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_bound_idx[:rand_i]:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# logging.info(f\"Take step {i1} and {i2}\")\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake_step(i1, i2):\n\u001b[1;32m    186\u001b[0m       \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    188\u001b[0m \u001b[39m# logging.info(\"Branch 3\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[85], line 140\u001b[0m, in \u001b[0;36mSVM.take_step\u001b[0;34m(self, i1, i2)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_threshold(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas[i1], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas[i2], k11, k12, k22)\n\u001b[1;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_non_bound(i1, i2)\n\u001b[0;32m--> 140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_error_cache(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malphas[i1], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49malphas[i2], i1, i2, old_b)\n\u001b[1;32m    141\u001b[0m \u001b[39m# self.alphas[i1] = self.alphas[i1]\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m# self.alphas[i2] = self.alphas[i2]\u001b[39;00m\n\u001b[1;32m    143\u001b[0m logging\u001b[39m.\u001b[39mwarning(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39malpha[\u001b[39m\u001b[39m{\u001b[39;00mi1\u001b[39m}\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas[i1]\u001b[39m}\u001b[39;00m\u001b[39m;\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39malpha[\u001b[39m\u001b[39m{\u001b[39;00mi2\u001b[39m}\u001b[39;00m\u001b[39m]: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malphas[i2]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39m#;\\t[{L},  {H}]\")\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[85], line 59\u001b[0m, in \u001b[0;36mSVM.update_error_cache\u001b[0;34m(self, alpha1_new, alpha2_new, i1, i2, old_b)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39m# old1 = self.errors[i1]\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m# old2 = self.errors[i2]\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# non_bound_indexes = self.non_bound_idx()\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# logging.info(non_bound_indexes)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnon_bound_idx:\n\u001b[0;32m---> 59\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors[i] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m delta1 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrbf(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx1, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX[i]) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     60\u001b[0m                     delta2 \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrbf(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx2, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX[i]) \u001b[39m+\u001b[39m \\\n\u001b[1;32m     61\u001b[0m                     old_b \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb\n",
      "Cell \u001b[0;32mIn[85], line 11\u001b[0m, in \u001b[0;36mSVM.rbf\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrbf\u001b[39m(\u001b[39mself\u001b[39m, x1, x2):\n\u001b[0;32m---> 11\u001b[0m   \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m (np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mnorm(x1 \u001b[39m-\u001b[39;49m x2) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m ))\n",

      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda/lib/python3.10/site-packages/numpy/linalg/linalg.py:2511\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2509\u001b[0m     sqnorm \u001b[39m=\u001b[39m x_real\u001b[39m.\u001b[39mdot(x_real) \u001b[39m+\u001b[39m x_imag\u001b[39m.\u001b[39mdot(x_imag)\n\u001b[1;32m   2510\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2511\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mdot(x)\n\u001b[1;32m   2512\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2513\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "svm = SVM(gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 0.80947809, 1.        , 1.        ,\n",
       "       1.        , 0.85065113, 1.        , 1.        , 1.        ,\n",
       "       1.        , 0.79975451, 1.        , 1.        , 0.87861863,\n",
       "       0.81198669, 1.        , 0.82096765, 1.        , 0.59007319,\n",
       "       0.84085772, 0.74522173, 0.81370073, 0.83507019, 0.8802041 ,\n",
       "       1.        , 1.        , 0.77072867, 1.        , 0.85471448,\n",
       "       0.67903993, 0.87244227, 1.        , 0.92560493, 1.        ,\n",
       "       0.79075291, 0.93983252, 0.84653669, 0.81896858, 0.71825389,\n",
       "       0.78184671, 0.87837353, 1.        , 1.        , 0.78365947,\n",
       "       1.        , 0.87252193, 0.82294334, 0.82162809, 0.85140974,\n",
       "       1.        , 1.        , 0.84402873, 0.96324973, 0.82215989,\n",
       "       1.        , 1.        , 0.91385412, 1.        , 1.        ,\n",
       "       0.88885188, 1.        , 1.        , 1.        , 0.86457123,\n",
       "       1.        , 0.86161105, 0.93721967, 0.90143117, 1.        ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.alphas"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpmSnc60Aa8F",
    "outputId": "9f9be904-2184-40d2-9baf-a4b84dcb399b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [

       "0.6333333333333333"
      ]
     },
     "execution_count": 61,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [

    "y_train_sklearn = np.array([str(y) for y in y_train])\n",
    "y_test_sklearn = np.array([str(y) for y in y_test])\n",
    "\n",

    "svc = SVC(kernel='rbf', gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svc.fit(x_train, y_train_sklearn)\n",
    "pred = svc.predict(x_test)\n",
    "accuracy_score(pred, y_test_sklearn)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "array([[-0.60025218, -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.72419966, -0.98163483, -1.        , -0.68263974, -1.        ,\n",
       "        -0.83516565, -1.        , -1.        , -1.        , -0.55357148,\n",
       "        -0.69610305, -0.59207909, -0.48033431, -0.40018773, -0.81683439,\n",
       "        -1.        , -0.87903817, -1.        , -0.7886276 , -1.        ,\n",
       "        -0.72968296, -1.        , -0.8364228 , -1.        , -0.80246817,\n",
       "        -0.51771468, -1.        , -0.60237807, -1.        , -1.        ,\n",
       "        -0.53678956, -1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.89720288,  0.71885341,  1.        ,  1.        ,\n",
       "         0.7814236 ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.91623355,  0.83567334,  1.        ,  0.90673732,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ]])"
      ]
     },
     "execution_count": 62,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [

    "svc.dual_coef_"

   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_simplified:\n",
    "    def __init__(self, C=1.0, gamma=0.1, tol=1e-3, max_iter=1200):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.alphas = None\n",
    "        self.b = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.n_iter_ = 0\n",
    "\n",
    "    def rbf_kernel(self, x1, x2):\n",
    "      return np.exp(-self.gamma * (np.linalg.norm(x1 - x2) ** 2))\n",
    "    \n",
    "    def compute_error(self, n_samples, y, i, K):\n",
    "      err = self.b - y[i]\n",
    "      for j in range(n_samples):\n",
    "        err += self.alphas[j] * y[j] * K[j, i]\n",
    "      return err\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "      # random.seed(42)\n",
    "      n_samples, n_features = X.shape\n",
    "\n",
    "      K = np.zeros((n_samples, n_samples))\n",
    "      for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "          K[i,j] = self.rbf_kernel(X[i], X[j])\n",
    "      \n",
    "      self.alphas = np.zeros(n_samples)\n",
    "      self.b = 0\n",
    "      passes = 0\n",
    "      while passes < self.max_iter:\n",
    "        self.n_iter_ += 1\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(n_samples):\n",
    "          Ei = np.sum(self.alphas*y*K[i,:]) + self.b - y[i]\n",
    "          # Ei = self.compute_error(n_samples, y, i, K)\n",
    "          # Ei = np.sum(np.dot(np.dot(self.alphas, y), K[i,:])) +self.b - y[i]\n",
    "          # if abs(ei - Ei)>0.00001:\n",
    "          #   print(Ei, ei)\n",
    "          if (((y[i]*Ei < -self.tol) and (self.alphas[i] < self.C)) or ((y[i]*Ei>self.tol) and (self.alphas[i]>0))):\n",
    "            j = random.choice(list(range(i))+list(range(i+1,n_samples)))\n",
    "            Ej = np.sum(self.alphas*y*K[j, :]) + self.b - y[j]\n",
    "            # Ej = self.compute_error(n_samples, y, j, K)\n",
    "            # Ej = np.sum(np.dot(np.dot(self.alphas, y), K[j,:])) +self.b - y[j]\n",
    "            alpha_i_old = self.alphas[i]\n",
    "            alpha_j_old = self.alphas[j]\n",
    "            if (y[i]!=y[j]):\n",
    "              L = max(0, self.alphas[j] - self.alphas[i])\n",
    "              H = min(self.C, self.C + self.alphas[j] - self.alphas[i])\n",
    "            else:\n",
    "              L = max(0, self.alphas[i] + self.alphas[j] - self.C)\n",
    "              H = min(self.C, self.alphas[i] + self.alphas[j])\n",
    "            if L==H:\n",
    "              continue\n",
    "            eta = 2 * K[i,j] - K[i,i] - K[j,j]\n",
    "            if eta>=0:\n",
    "              continue\n",
    "            self.alphas[j] -= y[j]*(Ei-Ej)/eta\n",
    "            self.alphas[j] = max(L, min(H, self.alphas[j]))\n",
    "\n",
    "            if (abs(self.alphas[j] - alpha_j_old) < 0.00001):\n",
    "              continue\n",
    "            self.alphas[i] += y[i]*y[j]*(alpha_j_old - self.alphas[j])\n",
    "            \n",
    "            b1 = self.b - Ei - y[i]*(self.alphas[i]-alpha_i_old)*K[i,i] - y[j]*(self.alphas[j]-alpha_j_old)*K[i,j]\n",
    "            b2 = self.b - Ej - y[i]*(self.alphas[i]-alpha_i_old)*K[i,j] - y[j]*(self.alphas[j]-alpha_j_old)*K[j,j]\n",
    "            if (0 < self.alphas[i] and self.alphas[i]<self.C):\n",
    "              self.b = b1\n",
    "            elif (0<self.alphas[j] and self.alphas[j]<self.C):\n",
    "              self.b = b2\n",
    "            else:\n",
    "              self.b = (b1 + b2)/2\n",
    "            num_changed_alphas += 1\n",
    "        if (num_changed_alphas == 0):\n",
    "          passes+= 1\n",
    "        else:\n",
    "          passes = 0\n",
    "      sv_idx = (self.alphas>0)\n",
    "      self.sv_idx = sv_idx\n",
    "      self.alphas = self.alphas[sv_idx]\n",
    "      self.support_vectors = X[sv_idx]\n",
    "      self.support_vector_labels = y[sv_idx]\n",
    "    def predict(self, X):\n",
    "      y_pred = np.zeros(len(X))\n",
    "      for i in range(len(X)):\n",
    "        s = self.b\n",
    "        for alpha, sv_y, sv_x in zip(self.alphas, self.support_vector_labels, self.support_vectors):\n",
    "          s += alpha * sv_y * self.rbf_kernel(X[i], sv_x)\n",
    "        y_pred[i] = s\n",
    "      return np.sign(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [

       "0.36666666666666664"
      ]
     },
     "execution_count": 64,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [

    "svm = SVM_simplified(gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "accuracy_score(pred, y_test)"

   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
