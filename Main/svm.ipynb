{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "40ygIDXEhjav"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import glob2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from random import randrange\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='./log.log',level=10, filemode = 'w', force=True, format='%(asctime)s   %(funcName)s - %(levelname)s:%(message)s')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LXMhyoM3Wnq4"
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_cat = r'./PetImages/Cat/**'\n",
    "link_dog = r'./PetImages/Dog/**'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n",
      "12501\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100\n",
    "images  = []\n",
    "labels = []\n",
    "list_cat = glob2.glob(link_cat)\n",
    "print(len(list_cat))\n",
    "for i in range(n_samples):\n",
    "    if('jpg' in list_cat[i]):\n",
    "        img = Image.open(list_cat[i]).convert('RGB')\n",
    "        img = img.resize((400,400), Image.LANCZOS)\n",
    "        if len(np.array(img).shape)  == 3:\n",
    "            images.append(np.array(img))\n",
    "            labels.append(1)\n",
    "            \n",
    "list_dog = glob2.glob(link_dog)\n",
    "print(len(list_dog))\n",
    "for i in range(n_samples):\n",
    "    if('jpg' in list_dog[i]):\n",
    "        img = Image.open(list_dog[i]).convert('RGB')\n",
    "        img = img.resize((400,400), Image.LANCZOS)\n",
    "        if len(np.array(img).shape)  == 3:\n",
    "            images.append(np.array(img))\n",
    "            labels.append(-1)\n",
    "\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "for index in range(len(images)):\n",
    "    if images[index].shape[2] != 3:\n",
    "        print(index, images[index].shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "oGqEcWO3NQs1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x.flatten() for x in X_train])\n",
    "x_test = np.array([x.flatten() for x in X_test])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1,  1,  1, -1, -1,  1,  1, -1, -1,  1, -1,  1,  1,  1,  1, -1,\n",
       "       -1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1, -1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1, -1,\n",
       "        1,  1,  1, -1,  1, -1,  1, -1, -1, -1, -1,  1,  1, -1, -1, -1,  1,\n",
       "       -1, -1,  1,  1, -1,  1,  1, -1,  1, -1, -1,  1,  1,  1, -1, -1, -1,\n",
       "        1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1, -1, -1,  1,  1,\n",
       "        1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1,\n",
       "        1, -1,  1,  1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "  def __init__(self, C=1.0, gamma=0.1, tol=1e-3, max_iter=1200):\n",
    "    self.C = C\n",
    "    self.gamma = gamma\n",
    "    self.tol = tol\n",
    "    self.max_iter = max_iter\n",
    "    self.n_iter = 0\n",
    "    self.eps = 1e-3\n",
    "\n",
    "  def rbf(self, x1, x2):\n",
    "    return np.exp(-self.gamma * (np.linalg.norm(x1 - x2) **2 ))\n",
    "  \n",
    "  def output(self, x, X, y, n_samples):\n",
    "    return np.sum([self.alphas[i] * y[i] * self.rbf(X[i], x) for i in range(n_samples)]) - self.b\n",
    "\n",
    "  def get_error(self, i, X, y):\n",
    "    if self.non_bound[i]:\n",
    "      return self.errors[i]\n",
    "    else:\n",
    "      op = self.output(X[i], X, y, self.n_samples) - y[i]\n",
    "      self.errors[i] = op\n",
    "      return op  \n",
    "\n",
    "  def predict(self, X):\n",
    "    pred = []\n",
    "    for x in X:\n",
    "      pred.append(np.sign(self.output(x, self.support_vectors, self.support_vector_labels, self.n_vector)))\n",
    "    return pred\n",
    "    \n",
    "  def compute_L_H(self):\n",
    "    if self.y1 != self.y2:\n",
    "      L = max(0, self.alpha2 - self.alpha1)\n",
    "      H = min(self.C, self.C + self.alpha2 - self.alpha1)\n",
    "    else:\n",
    "      L = max(0, self.alpha2 + self.alpha1 - self.C)\n",
    "      H = min(self.C, self.alpha2 + self.alpha1)\n",
    "    return L, H\n",
    "  \n",
    "  def compute_threshold(self, alpha1_new, alpha2_new, k11, k12, k22):\n",
    "    b1 = self.E1 + self.y1 * (alpha1_new - self.alpha1) * k11 + \\\n",
    "        self.y2 * (alpha2_new - self.alpha2) * k12 + self.b\n",
    "    b2 = self.E2 + self.y1 * (alpha1_new - self.alpha1) * k12 + \\\n",
    "        self.y2 * (alpha2_new - self.alpha2) * k22 + self.b\n",
    "\n",
    "    if 0 < alpha1_new and alpha1_new < self.C:\n",
    "      return b1\n",
    "    if 0 < alpha2_new and alpha2_new < self.C:\n",
    "      return b2\n",
    "    return (b1 + b2)/2.0\n",
    "    \n",
    "  def update_error_cache(self, alpha1_new, alpha2_new, old_b, X):\n",
    "    delta1 = self.y1 * (alpha1_new - self.alpha1)\n",
    "    delta2 = self.y2 * (alpha2_new - self.alpha2)\n",
    "    for i in self.non_bound_idx:\n",
    "      self.errors[i] += delta1 * self.rbf(self.x1, X[i]) + \\\n",
    "                        delta2 * self.rbf(self.x2, X[i]) + \\\n",
    "                        old_b - self.b\n",
    "\n",
    "    \n",
    "  def update_non_bound(self, i1, i2):\n",
    "    if 0 < self.alphas[i1] and self.alphas[i1] < self.C:\n",
    "      self.non_bound[i1] = True\n",
    "      if i1 not in self.non_bound_idx:\n",
    "        self.non_bound_idx.append(i1)\n",
    "    else:\n",
    "      self.non_bound[i1] = False\n",
    "      if i1 in self.non_bound_idx:\n",
    "        self.non_bound_idx.remove(i1)\n",
    "      \n",
    "    if 0 < self.alphas[i2] and self.alphas[i2] < self.C:\n",
    "      self.non_bound[i2] = True\n",
    "      if i2 not in self.non_bound_idx:\n",
    "        self.non_bound_idx.append(i2)\n",
    "    else:\n",
    "      self.non_bound[i2] = False\n",
    "      if i2 in self.non_bound_idx:\n",
    "        self.non_bound_idx.remove(i2)\n",
    "\n",
    "    \n",
    "  def get_alpha2(self, L, H, k11, k12, k22, s):\n",
    "    eta = k11 + k22 - 2 * k12\n",
    "    if eta > 0:\n",
    "      alpha2_new = self.alpha2 + self.y2 * (self.E1-self.E2)/eta\n",
    "      alpha2_new = min(H, max(L, alpha2_new))\n",
    "    else:\n",
    "      print(\"ETA < 0\")\n",
    "      logging.error(\"ETA <= 0\")\n",
    "      f1 = self.y1*(self.E1 + self.b) - self.alpha1*k11 - s*self.alpha2*k12\n",
    "      f2 = self.y2*(self.E2 + self.b) - s*self.alpha1*k12 - self.alpha2*k22\n",
    "      L1 = self.alpha1 + s*(self.alpha2-L)\n",
    "      H1 = self.alpha1 + s*(self.alpha2-H)\n",
    "      Lobj = L1*f1 + L*f2 + 0.5*(L1**2)*k11 + 0.5*(L**2)*k22 + s*L*L1*k12\n",
    "      Hobj = H1*f1 + H*f2 + 0.5*(H1**2)*k11 + 0.5*(H**2)*k22 + s*H*H1*k12\n",
    "      if Lobj < Hobj - self.eps:\n",
    "        alpha2_new = L\n",
    "      elif Lobj > Hobj + self.eps:\n",
    "        alpha2_new = H\n",
    "      else:\n",
    "        alpha2_new = self.alpha2\n",
    "    return alpha2_new\n",
    "    \n",
    "  def take_step(self, i1, i2, X, y):\n",
    "    if i1 == i2:\n",
    "      return 0\n",
    "    self.y2 = y[i2]\n",
    "    self.alpha2 = self.alphas[i2]\n",
    "    self.x2 = X[i2]\n",
    "    self.E2 = self.get_error(i2, X, y)\n",
    "    s = self.y1 * self.y2\n",
    "    L, H = self.compute_L_H()\n",
    "    if L==H:\n",
    "      return 0\n",
    "    k11 = self.rbf(self.x1, self.x1)\n",
    "    k12 = self.rbf(self.x1, self.x2)\n",
    "    k22 = self.rbf(self.x2, self.x2)\n",
    "    self.alphas[i2] = self.get_alpha2(L, H, k11, k12, k22, s)\n",
    "    if abs(self.alphas[i2] -self.alpha2) < self.eps * (self.alphas[i2] + self.alpha2 + self.eps):\n",
    "    # if abs(self.alphas[i2] - self.alpha2) < self.eps: # * (alpha2_new + self.alpha2 + self.eps):\n",
    "      return 0\n",
    "    self.alphas[i1] = self.alpha1 + s * (self.alpha2 - self.alphas[i2])\n",
    "    old_b = self.b\n",
    "    self.b = self.compute_threshold(self.alphas[i1], self.alphas[i2], k11, k12, k22)\n",
    "    self.update_non_bound(i1, i2)\n",
    "    self.update_error_cache(self.alphas[i1], self.alphas[i2], old_b, X)\n",
    "    logging.warning(f\"alpha[{i1}]: {self.alphas[i1]};\\talpha[{i2}]: {self.alphas[i2]}\") #;\\t[{L},  {H}]\")\n",
    "    return 1\n",
    "  \n",
    "  def second_choice_heuristic(self, X ,y):\n",
    "    i2 = -1\n",
    "    m = 0\n",
    "    for i in self.non_bound_idx:\n",
    "      step = abs(self.get_error(i, X, y) - self.E1)\n",
    "      if step > m:\n",
    "        m = step\n",
    "        i2 = i\n",
    "    return i2\n",
    "\n",
    "  def examine_example(self, i1, X, y):\n",
    "    self.y1 = y[i1]\n",
    "    self.alpha1 = self.alphas[i1]\n",
    "    self.x1 = X[i1]\n",
    "    self.E1 = self.get_error(i1, X, y)\n",
    "    r2 = self.E1 * self.y1\n",
    "    if (r2 < -self.tol and self.alpha1 < self.C) or \\\n",
    "      (r2 > self.tol and self.alpha1 > 0):\n",
    "      n_non_bound = len(self.non_bound_idx)\n",
    "      if (n_non_bound > 1):\n",
    "        i2 = self.second_choice_heuristic(X, y)\n",
    "        if i2 != -1:\n",
    "          if self.take_step(i1, i2, X, y):\n",
    "            return 1\n",
    "        \n",
    "      if n_non_bound > 0:\n",
    "        rand_i = randrange(n_non_bound)\n",
    "        for i2 in self.non_bound_idx[rand_i:] + self.non_bound_idx[:rand_i]:\n",
    "          if self.take_step(i1, i2, X, y):\n",
    "            return 1\n",
    "          \n",
    "      rand_i = randrange(self.n_samples)\n",
    "      all_indexes = list(range(self.n_samples))\n",
    "      for i2 in all_indexes[rand_i:] + all_indexes[:rand_i]:\n",
    "        if self.take_step(i1, i2, X, y):\n",
    "          return 1\n",
    "    return 0\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    random.seed(42)\n",
    "    self.n_samples, self.n_features = X.shape\n",
    "    self.errors = np.zeros(self.n_samples)\n",
    "    self.alphas = np.zeros(self.n_samples)\n",
    "    self.non_bound = np.array([False for _ in range(self.n_samples)])\n",
    "    self.non_bound_idx = []\n",
    "    self.b = 0\n",
    "    num_changed = 0\n",
    "    examine_all = True\n",
    "    self.n_iter = 0\n",
    "    while num_changed > 0 or examine_all:\n",
    "      self.n_iter += 1\n",
    "      logging.debug(f\"N iter: {self.n_iter}\")\n",
    "      logging.debug(f\"examine_all: {examine_all}, numchanged: {num_changed}\")\n",
    "      num_changed = 0\n",
    "      if examine_all:\n",
    "        for i in range(self.n_samples):\n",
    "          num_changed += self.examine_example(i, X, y)\n",
    "      else:\n",
    "        for i in range(self.n_samples):\n",
    "          if 0 < self.alphas[i] < self.C:\n",
    "            num_changed += self.examine_example(i, X, y)\n",
    "  \n",
    "      if examine_all:\n",
    "        examine_all = False\n",
    "      elif num_changed == 0:\n",
    "        examine_all = True\n",
    "        \n",
    "    sv_idx = (self.alphas > 0)\n",
    "    logging.info(f\"Filtering support vectors, there are {np.sum(sv_idx)} alphas\")\n",
    "    self.support_vectors = X[sv_idx]\n",
    "    self.support_vector_labels = y[sv_idx]\n",
    "    self.n_vector = np.sum(sv_idx)\n",
    "    logging.info(\"Done fitting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WPX7eu3l_--N",
    "outputId": "5c4d5586-0b7f-4f40-b357-58e80195bdfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVM(gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.74746624, 1.        ,\n",
       "       1.        , 1.        , 0.80516838, 1.        , 1.        ,\n",
       "       0.86705886, 1.        , 0.74145159, 0.97087387, 0.91620691,\n",
       "       0.95098247, 1.        , 1.        , 0.91638775, 1.        ,\n",
       "       0.89513098, 1.        , 1.        , 0.94194051, 1.        ,\n",
       "       0.85217767, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.82693439, 0.87285682, 0.90499535,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.980985  ,\n",
       "       1.        , 0.9778686 , 0.82254398, 1.        , 1.        ,\n",
       "       0.87961323, 1.        , 0.90719982, 0.8278083 , 1.        ,\n",
       "       1.        , 1.        , 0.96655958, 1.        , 0.75319986,\n",
       "       0.73985618, 1.        , 0.95333773, 1.        , 0.87216141,\n",
       "       0.99960746, 1.        , 0.90813167, 0.85200661, 1.        ,\n",
       "       1.        , 1.        , 0.83967082, 0.95720568, 1.        ,\n",
       "       1.        , 0.81539419, 1.        , 0.82546476, 0.84092472,\n",
       "       1.        , 0.75696123, 1.        , 1.        , 0.84720313,\n",
       "       0.88560857, 1.        , 1.        , 1.        , 0.85985587,\n",
       "       0.88578302, 1.        , 1.        , 0.90130546, 1.        ,\n",
       "       1.        , 0.8939223 , 0.80694735, 0.97560758, 1.        ,\n",
       "       0.98671531, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.80570762, 0.99086679, 0.94488598, 0.89979572, 0.97304138,\n",
       "       0.95876188, 0.75466303, 0.86561226, 1.        , 0.7751546 ,\n",
       "       1.        , 0.95116113, 1.        , 1.        , 0.69876025,\n",
       "       0.94330545, 0.89161508, 1.        , 1.        , 1.        ,\n",
       "       0.98557633, 0.92901455, 1.        , 1.        , 0.85934944,\n",
       "       1.        , 0.89738869, 1.        , 0.77973985, 1.        ,\n",
       "       1.        , 0.97903522, 1.        , 0.69350474, 0.91019862])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XpmSnc60Aa8F",
    "outputId": "9f9be904-2184-40d2-9baf-a4b84dcb399b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sklearn = np.array([str(y) for y in y_train])\n",
    "y_test_sklearn = np.array([str(y) for y in y_test])\n",
    "\n",
    "svc = SVC(kernel='rbf', gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svc.fit(x_train, y_train_sklearn)\n",
    "pred = svc.predict(x_test)\n",
    "accuracy_score(pred, y_test_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.        , -0.82843425, -0.5726144 , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -0.8254849 , -0.88337588, -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.65583543, -1.        ,\n",
       "        -0.90369915, -0.88973804, -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.80470053, -1.        , -0.91617143,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -0.9641108 , -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -1.        , -1.        , -0.98401891, -0.70382414, -0.45512111,\n",
       "        -0.46591773, -1.        , -0.7201633 , -0.77222499, -1.        ,\n",
       "        -1.        , -1.        , -1.        , -1.        , -1.        ,\n",
       "        -0.6719186 , -0.45709419, -1.        , -0.5303128 , -1.        ,\n",
       "        -1.        , -0.95088422,  1.        ,  0.76954314,  1.        ,\n",
       "         0.43627284,  0.81424457,  0.72364062,  1.        ,  0.77006602,\n",
       "         0.37368068,  0.92815889,  1.        ,  1.        ,  0.9286276 ,\n",
       "         1.        ,  0.70938583,  1.        ,  1.        ,  1.        ,\n",
       "         0.6904879 ,  0.74814359,  1.        ,  1.        ,  1.        ,\n",
       "         0.55550277,  0.40111069,  1.        ,  0.83893834,  0.48489225,\n",
       "         1.        ,  0.69388161,  1.        ,  1.        ,  0.75734465,\n",
       "         1.        ,  1.        ,  0.77463445,  0.53056255,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.66159028,  0.51890938,\n",
       "         0.90344125,  1.        ,  1.        ,  0.55516097,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.59797298,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.86380473,\n",
       "         1.        ,  0.38503751,  0.77939598,  1.        ,  0.57101527,\n",
       "         1.        ,  1.        ,  0.71764312,  0.96856047,  1.        ,\n",
       "         1.        ,  0.8899735 ,  0.63138798,  0.98263239]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.dual_coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_simplified:\n",
    "    def __init__(self, C=1.0, gamma=0.1, tol=1e-3, max_iter=1200):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.alphas = None\n",
    "        self.b = None\n",
    "        self.support_vectors = None\n",
    "        self.support_vector_labels = None\n",
    "        self.n_iter_ = 0\n",
    "\n",
    "    def rbf_kernel(self, x1, x2):\n",
    "      return np.exp(-self.gamma * (np.linalg.norm(x1 - x2) ** 2))\n",
    "    \n",
    "    def compute_error(self, n_samples, y, i, K):\n",
    "      err = self.b - y[i]\n",
    "      for j in range(n_samples):\n",
    "        err += self.alphas[j] * y[j] * K[j, i]\n",
    "      return err\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "      # random.seed(42)\n",
    "      n_samples, n_features = X.shape\n",
    "\n",
    "      K = np.zeros((n_samples, n_samples))\n",
    "      for i in range(n_samples):\n",
    "        for j in range(n_samples):\n",
    "          K[i,j] = self.rbf_kernel(X[i], X[j])\n",
    "      \n",
    "      self.alphas = np.zeros(n_samples)\n",
    "      self.b = 0\n",
    "      passes = 0\n",
    "      while passes < self.max_iter:\n",
    "        self.n_iter_ += 1\n",
    "        num_changed_alphas = 0\n",
    "        for i in range(n_samples):\n",
    "          Ei = np.sum(self.alphas*y*K[i,:]) + self.b - y[i]\n",
    "          # Ei = self.compute_error(n_samples, y, i, K)\n",
    "          # Ei = np.sum(np.dot(np.dot(self.alphas, y), K[i,:])) +self.b - y[i]\n",
    "          # if abs(ei - Ei)>0.00001:\n",
    "          #   print(Ei, ei)\n",
    "          if (((y[i]*Ei < -self.tol) and (self.alphas[i] < self.C)) or ((y[i]*Ei>self.tol) and (self.alphas[i]>0))):\n",
    "            j = random.choice(list(range(i))+list(range(i+1,n_samples)))\n",
    "            Ej = np.sum(self.alphas*y*K[j, :]) + self.b - y[j]\n",
    "            # Ej = self.compute_error(n_samples, y, j, K)\n",
    "            # Ej = np.sum(np.dot(np.dot(self.alphas, y), K[j,:])) +self.b - y[j]\n",
    "            alpha_i_old = self.alphas[i]\n",
    "            alpha_j_old = self.alphas[j]\n",
    "            if (y[i]!=y[j]):\n",
    "              L = max(0, self.alphas[j] - self.alphas[i])\n",
    "              H = min(self.C, self.C + self.alphas[j] - self.alphas[i])\n",
    "            else:\n",
    "              L = max(0, self.alphas[i] + self.alphas[j] - self.C)\n",
    "              H = min(self.C, self.alphas[i] + self.alphas[j])\n",
    "            if L==H:\n",
    "              continue\n",
    "            eta = 2 * K[i,j] - K[i,i] - K[j,j]\n",
    "            if eta>=0:\n",
    "              continue\n",
    "            self.alphas[j] -= y[j]*(Ei-Ej)/eta\n",
    "            self.alphas[j] = max(L, min(H, self.alphas[j]))\n",
    "\n",
    "            if (abs(self.alphas[j] - alpha_j_old) < 0.00001):\n",
    "              continue\n",
    "            self.alphas[i] += y[i]*y[j]*(alpha_j_old - self.alphas[j])\n",
    "            \n",
    "            b1 = self.b - Ei - y[i]*(self.alphas[i]-alpha_i_old)*K[i,i] - y[j]*(self.alphas[j]-alpha_j_old)*K[i,j]\n",
    "            b2 = self.b - Ej - y[i]*(self.alphas[i]-alpha_i_old)*K[i,j] - y[j]*(self.alphas[j]-alpha_j_old)*K[j,j]\n",
    "            if (0 < self.alphas[i] and self.alphas[i]<self.C):\n",
    "              self.b = b1\n",
    "            elif (0<self.alphas[j] and self.alphas[j]<self.C):\n",
    "              self.b = b2\n",
    "            else:\n",
    "              self.b = (b1 + b2)/2\n",
    "            num_changed_alphas += 1\n",
    "        if (num_changed_alphas == 0):\n",
    "          passes+= 1\n",
    "        else:\n",
    "          passes = 0\n",
    "      sv_idx = (self.alphas>0)\n",
    "      self.sv_idx = sv_idx\n",
    "      self.alphas = self.alphas[sv_idx]\n",
    "      self.support_vectors = X[sv_idx]\n",
    "      self.support_vector_labels = y[sv_idx]\n",
    "    def predict(self, X):\n",
    "      y_pred = np.zeros(len(X))\n",
    "      for i in range(len(X)):\n",
    "        s = self.b\n",
    "        for alpha, sv_y, sv_x in zip(self.alphas, self.support_vector_labels, self.support_vectors):\n",
    "          s += alpha * sv_y * self.rbf_kernel(X[i], sv_x)\n",
    "        y_pred[i] = s\n",
    "      return np.sign(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVM_simplified(gamma = 1/(x_train.shape[1]*x_train.var()))\n",
    "svm.fit(x_train, y_train)\n",
    "pred = svm.predict(x_test)\n",
    "accuracy_score(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78087783, 1.        , 0.90441755, 1.        , 1.        ,\n",
       "       1.        , 0.80462725, 0.96789864, 0.97564715, 1.        ,\n",
       "       0.9533935 , 0.82666611, 1.        , 0.97482102, 0.95767906,\n",
       "       0.99440895, 0.66167992, 0.93938625, 1.        , 0.98495043,\n",
       "       0.93323013, 0.80266313, 0.96813827, 1.        , 1.        ,\n",
       "       1.        , 0.81618037, 1.        , 0.93902046, 1.        ,\n",
       "       0.81658417, 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.81195137, 0.95561353, 1.        ,\n",
       "       0.73565639, 0.96610003, 0.98404775, 0.65788146, 1.        ,\n",
       "       1.        , 0.86861758, 1.        , 1.        , 0.82392483,\n",
       "       1.        , 0.948039  , 1.        , 0.84502243, 1.        ,\n",
       "       1.        , 1.        , 0.91867396, 1.        , 1.        ,\n",
       "       1.        , 1.        , 0.96081965, 1.        , 0.98849993,\n",
       "       0.93842456, 0.93855164, 0.73510586, 1.        , 1.        ,\n",
       "       0.87167585, 0.81594497, 0.93297548, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.67095855, 0.93347405,\n",
       "       0.99496325, 0.90930521, 1.        , 1.        , 1.        ,\n",
       "       0.9436806 , 0.88453051, 0.92425593, 0.93111711, 0.89477537,\n",
       "       0.90003805, 1.        , 1.        , 0.84416303, 0.99551665,\n",
       "       0.93763708, 0.88640849, 0.63473261, 0.92277449, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 0.98437871,\n",
       "       1.        , 0.98201217, 0.90148489, 0.9282041 , 0.89419152,\n",
       "       1.        , 1.        , 0.97310657, 0.91594978, 1.        ,\n",
       "       0.99860495, 1.        , 0.67524248, 0.80730672, 1.        ,\n",
       "       1.        , 0.72935851, 0.79231289, 0.92868278, 1.        ,\n",
       "       1.        , 0.6941089 , 0.95727165, 0.52491318, 1.        ,\n",
       "       0.80301948, 0.99849271, 0.81472687, 1.        , 1.        ,\n",
       "       0.95071184, 0.89862506, 1.        , 1.        , 0.96289988])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.alphas"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
