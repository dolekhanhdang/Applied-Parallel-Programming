{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "40ygIDXEhjav"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import math\n",
    "from numba import cuda\n",
    "from skimage import exposure\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXMhyoM3Wnq4"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "mkzNZxxdhsa5"
   },
   "outputs": [],
   "source": [
    "class SVM():\n",
    "  def __init__(self,C=1.0):\n",
    "    # C error terms\n",
    "    self.C = C\n",
    "    self.w = 0\n",
    "    self.b = 0\n",
    "\n",
    "  # Hinge Loss Function / Calculation\n",
    "  def hingeloss(self, w, b, x, y):\n",
    "    # Regularizer term\n",
    "    reg = 0.5 * (w * w)\n",
    "\n",
    "    for i in range(x.shape[0]):\n",
    "      # Optimization term\n",
    "      opt_term = y[i] * ((np.dot(w, x[i])) + b)\n",
    "\n",
    "      # calculating loss\n",
    "      loss = reg + self.C * max(0, 1-opt_term)\n",
    "    return loss[0][0]\n",
    "\n",
    "  def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
    "    # The number of features in X\n",
    "    number_of_features = X.shape[1]\n",
    "\n",
    "    # The number of Samples in X\n",
    "    number_of_samples = X.shape[0]\n",
    "\n",
    "    c = self.C\n",
    "\n",
    "    # Creating ids from 0 to number_of_samples - 1\n",
    "    ids = np.arange(number_of_samples)\n",
    "\n",
    "    # Shuffling the samples randomly\n",
    "    np.random.shuffle(ids)\n",
    "\n",
    "    # creating an array of zeros\n",
    "    w = np.zeros((1, number_of_features))\n",
    "    b = 0\n",
    "    losses = []\n",
    "\n",
    "    # Gradient Descent logic\n",
    "    for i in range(epochs):\n",
    "      # Calculating the Hinge Loss\n",
    "      l = self.hingeloss(w, b, X, Y)\n",
    "\n",
    "      # Appending all losses \n",
    "      losses.append(l)\n",
    "      \n",
    "      # Starting from 0 to the number of samples with batch_size as interval\n",
    "      for batch_initial in range(0, number_of_samples, batch_size):\n",
    "        gradw = 0\n",
    "        gradb = 0\n",
    "\n",
    "        for j in range(batch_initial, batch_initial + batch_size):\n",
    "          if j < number_of_samples:\n",
    "            x = ids[j]\n",
    "            ti = Y[x] * (np.dot(w, X[x].T) + b)\n",
    "\n",
    "            if ti > 1:\n",
    "              gradw += 0\n",
    "              gradb += 0\n",
    "            else:\n",
    "              # Calculating the gradients\n",
    "              #w.r.t w \n",
    "              gradw += c * Y[x] * X[x]\n",
    "              # w.r.t b\n",
    "              gradb += c * Y[x]\n",
    "\n",
    "        # Updating weights and bias\n",
    "        w = w - learning_rate * w + learning_rate * gradw\n",
    "        b = b + learning_rate * gradb\n",
    "\n",
    "    self.w = w\n",
    "    self.b = b\n",
    "\n",
    "    return self.w, self.b, losses\n",
    "\n",
    "  def predict(self, X):\n",
    "    prediction = np.dot(X, self.w[0]) + self.b # w.x + b\n",
    "    return np.sign(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKFm3J8JWqPp"
   },
   "source": [
    "# HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "6elbwjp4WrPD"
   },
   "outputs": [],
   "source": [
    "class HOG:\n",
    "    def __init__(self, blockSize, cellSize, nbins, sbins, threadsperblock):\n",
    "        self.blockSize       = blockSize\n",
    "        self.cellSize        = cellSize\n",
    "        self.nbins           = nbins\n",
    "        self.sbins           = sbins\n",
    "        self.threadsperblock = threadsperblock\n",
    "    \n",
    "    @staticmethod\n",
    "    @cuda.jit\n",
    "    def __gray_kernel(input, width, height, channel, gray):\n",
    "        row, col = cuda.grid(2)\n",
    "        if row >= height or col >= width or channel != 3:\n",
    "            return\n",
    "        rgb = input[row][col]\n",
    "        gray[row][col] = 0.299*rgb[0] + 0.587*rgb[1] + 0.114*rgb[2]\n",
    "    \n",
    "    def __gray(self):\n",
    "        picture = self.picture_array\n",
    "        # Memory Allocation\n",
    "        blockspergrid_x = math.ceil(self.picture_array.shape[0] / self.threadsperblock[0])\n",
    "        blockspergrid_y = math.ceil(self.picture_array.shape[1] / self.threadsperblock[1])\n",
    "        blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "        gray_dev   = np.empty([self.height, self.width],dtype = float)\n",
    "        input_dev   = cuda.to_device(self.picture_array)\n",
    "        gray_device = cuda.device_array_like(gray_dev)\n",
    "        kernel = self.__gray_kernel\n",
    "        kernel[blockspergrid, self.threadsperblock](input_dev, self.width, self.height, self.channel, gray_device)\n",
    "        gray_dev = gray_device.copy_to_host()\n",
    "        self.gray = gray_dev\n",
    "    \n",
    "    @staticmethod\n",
    "    @cuda.jit\n",
    "    def __calc_gradient_kernel(input, width, height, output_x, output_y):\n",
    "      row, col = cuda.grid(2)\n",
    "      if (row>=height) or (col>=width):\n",
    "        return\n",
    "      for i in range(-1,2):\n",
    "        pixel_r = row + i\n",
    "        pixel_r = min(max(0, pixel_r), height - 1)\n",
    "        output_y[row, col] += input[pixel_r,col] * i\n",
    "\n",
    "        pixel_c = col + i\n",
    "        pixel_c = min(max(0, pixel_c), width - 1)\n",
    "        output_x[row,col] += input[row,pixel_c] * i\n",
    "        \n",
    "    def __calc_gradient(self):\n",
    "        blockspergrid_x = math.ceil(self.picture_array.shape[0] / self.threadsperblock[0])\n",
    "        blockspergrid_y = math.ceil(self.picture_array.shape[1] / self.threadsperblock[1])\n",
    "        blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "        gradient_x_dev = np.zeros((self.height, self.width))\n",
    "        gradient_y_dev = np.zeros((self.height, self.width))\n",
    "\n",
    "        gradient_x_device = cuda.to_device(gradient_x_dev)\n",
    "        gradient_y_device = cuda.to_device(gradient_y_dev)\n",
    "        gray_device       = cuda.to_device(self.gray)\n",
    "        self.__calc_gradient_kernel[blockspergrid, self.threadsperblock]\\\n",
    "                (gray_device, self.width, self.height, gradient_x_device, gradient_y_device)\n",
    "\n",
    "        gradient_x_dev = gradient_x_device.copy_to_host()\n",
    "        gradient_y_dev = gradient_y_device.copy_to_host()\n",
    "        return gradient_x_dev, gradient_y_dev\n",
    "    \n",
    "    def __calc_direc_mag(self):\n",
    "        self.__gray()\n",
    "        gradient_x, gradient_y = self.__calc_gradient()\n",
    "        self.magnitude = np.sqrt(np.square(gradient_x)+np.square(gradient_y))\n",
    "        self.direction = np.mod(np.add(360, np.rad2deg(np.arctan2(np.array(gradient_y), np.array(gradient_x)))), 360)\n",
    "    \n",
    "    @staticmethod\n",
    "    @cuda.jit\n",
    "    def __hist_kernel(direction, magnitude, width, height, sbin, cell_size, result_out):    \n",
    "        cur_r, cur_c  = cuda.grid(2)\n",
    "\n",
    "        idy   = int(cur_r//cell_size[0])\n",
    "        idx   = int(cur_c//cell_size[1])\n",
    "        # kiểm tra\n",
    "        if cur_r>=height or cur_c>= width:\n",
    "            return \n",
    "        thread_direction = direction[cur_r][cur_c]\n",
    "        thread_mag       = magnitude[cur_r][cur_c]\n",
    "        # chia lấy phần nguyên và phần dư\n",
    "        quotient  = int(thread_direction//sbin)\n",
    "        remainder =     thread_direction % sbin\n",
    "\n",
    "        if remainder==0:\n",
    "            cuda.atomic.add(result_out, (idy, idx, quotient), thread_mag)\n",
    "        else:\n",
    "            first_bin = quotient\n",
    "\n",
    "            second_bin   = first_bin+1\n",
    "            need_to_add    = thread_mag*((second_bin*sbin - thread_direction)/(second_bin*sbin - first_bin*sbin))\n",
    "            cuda.atomic.add(result_out, (idy, idx, first_bin), need_to_add)\n",
    "\n",
    "            second_bin_idx = second_bin\n",
    "            if second_bin > 8:\n",
    "                second_bin_idx = 0\n",
    "            need_to_add_2  = thread_mag*((thread_direction - first_bin*sbin)/(second_bin*sbin - first_bin*sbin))   \n",
    "            cuda.atomic.add(result_out, (idy, idx, second_bin_idx), need_to_add_2)\n",
    "    \n",
    "    def __all_hist(self):\n",
    "        blockspergrid_x = math.ceil(self.picture_array.shape[0] / self.threadsperblock[0])\n",
    "        blockspergrid_y = math.ceil(self.picture_array.shape[1] / self.threadsperblock[1])\n",
    "        blockspergrid = (blockspergrid_x, blockspergrid_y)\n",
    "        hist_dev    = np.empty([self.n_cell[0], self.n_cell[1], self.nbins],dtype = np.float64)\n",
    "        d_direction = cuda.to_device(self.direction)\n",
    "        d_magnitude = cuda.to_device(self.magnitude)\n",
    "        d_cell_size = cuda.to_device(self.cellSize)\n",
    "        hist_device = cuda.device_array_like(hist_dev)\n",
    "        kernel = self.__hist_kernel\n",
    "        kernel[blockspergrid, self.threadsperblock]\\\n",
    "                            (d_direction, d_magnitude, self.width, self.height, self.sbins, d_cell_size, hist_device)\n",
    "        self.hist = hist_device.copy_to_host()\n",
    "        \n",
    "        \n",
    "    def compute_HOG(self, picture):\n",
    "        self.picture_array = picture\n",
    "        self.height, self.width, self.channel = self.picture_array.shape\n",
    "        self.n_cell  = (self.height//self.cellSize[0], self.width//self.cellSize[1])\n",
    "        self.n_block = (self.n_cell[0] - self.blockSize[0] + 1, self.n_cell[1] - self.blockSize[1] + 1)\n",
    "        \n",
    "        self.__calc_direc_mag()\n",
    "        self.__all_hist()\n",
    "        norm_array_size = self.n_block[0] * self.n_block[1] * self.blockSize[0] * self.blockSize[1] * self.nbins\n",
    "        l2 = np.empty(self.n_block)\n",
    "        for i in range(self.n_block[0]):\n",
    "            for j in range(self.n_block[1]):\n",
    "                l2[i][j] = math.sqrt(np.sum(np.square(self.hist[i:i+2, j:j+2])))\n",
    "        norm_block = np.zeros((self.n_block[0], self.n_block[1], self.blockSize[0], self.blockSize[1], self.nbins))\n",
    "        for y in range(self.n_block[0]):\n",
    "            for x in range(self.n_block[1]):\n",
    "                out = self.hist[y: y + self.blockSize[0], x: x + self.blockSize[1]] / (l2[y][x] + 1)\n",
    "                norm_block[y][x] = out\n",
    "        self.HOG        = norm_block.flatten()\n",
    "        self.norm_block = norm_block\n",
    "        return self.HOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igvtzXRlX032"
   },
   "source": [
    "# Đọc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYGSfLIXNwe2",
    "outputId": "a0cfee6f-2b63-44f7-f173-6e5a8149ee85"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "oSYXaWpQN_J9"
   },
   "outputs": [],
   "source": [
    "cell_size = (8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "cKbrU0kbM0j6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12501\n"
     ]
    }
   ],
   "source": [
    "list_cat = glob2.glob(r\"C:\\Users\\dolek\\Documents\\GitHub\\Applied-Parallel-Programming\\Sequential\\Picture\\PetImages\\Cat\\**\")\n",
    "print(len(list_cat))\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for i in range(100):\n",
    "    img = Image.open(list_cat[i])\n",
    "    img = img.resize((400,400), Image.LANCZOS)\n",
    "    images.append(np.array(img))\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "5X7TNxfEM0j7"
   },
   "outputs": [],
   "source": [
    "list_dog = glob2.glob(r\"C:\\Users\\dolek\\Documents\\GitHub\\Applied-Parallel-Programming\\Sequential\\Picture\\PetImages\\Dog\\**\")\n",
    "\n",
    "for i in range(100):\n",
    "    img = Image.open(list_dog[i])\n",
    "    img = img.resize((400,400), Image.LANCZOS)\n",
    "    images.append(np.array(img))\n",
    "    labels.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "HWeY3Or8jakZ"
   },
   "outputs": [],
   "source": [
    "X = np.array(images)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "oGqEcWO3NQs1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "onBGKDPfQHjG"
   },
   "outputs": [],
   "source": [
    "def big_fit(X_train, y_train, hog, svm):\n",
    "  x_train = []\n",
    "  t = 0\n",
    "  for x in X_train:\n",
    "    print(t)\n",
    "    x_train.append(hog.compute_HOG(x))\n",
    "    t+=1\n",
    "  x_train = np.array(x_train)\n",
    "  svm.fit(x_train, y_train)\n",
    "\n",
    "def big_predict(X_test, y_test, hog, svm):\n",
    "  x_test = []\n",
    "  t = 0\n",
    "  for x in X_test:\n",
    "    print(t)\n",
    "    x_test.append(hog.compute_HOG(x))\n",
    "    t+=1\n",
    "  x_test = np.array(x_test)\n",
    "  return svm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "X-UiPA4jQ96W"
   },
   "outputs": [],
   "source": [
    "hog = HOG((2,2), (8,8), 9, 40,(32,32))\n",
    "svm = SVM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "big_fit(X_train, y_train, hog, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "test_predict = big_predict(X_test, y_test, hog, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5333333333333333"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "TZuzNXO1eKOo"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xFslcBJ7eOkI"
   },
   "outputs": [],
   "source": [
    "# svm = SVC(kernel='linear', C=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ZkVTFBsWUQKQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scipy import ndimage\n",
    "from shutil import copyfile\n",
    "from tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "hMyrDJ5BUPfB"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(400,400,3))\n",
    "x =  tf.keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.Conv2D(256, (3,3), activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
    "\n",
    "\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x) \n",
    "x = tf.keras.layers.Dense(2, activation='softmax')(x) \n",
    "\n",
    "model = Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "DBB-8fxMUgeE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "PFfaTnHPmFRT"
   },
   "outputs": [],
   "source": [
    "# X_train = tf.keras.layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "b3AV4kESmih-"
   },
   "outputs": [],
   "source": [
    "y_t = np.array([0 if x==-1 else 1 for x in y_train])\n",
    "y_te = np.array([0 if x==-1 else 1 for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jrJ8QnSU2Zr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 6/14 [===========>..................] - ETA: 1:31 - loss: 36312.1094 - accuracy: 0.4500"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_t, batch_size = 10,\n",
    "\tepochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
