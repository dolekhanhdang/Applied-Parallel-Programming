{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "40ygIDXEhjav"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob2\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import math\n",
        "from skimage import exposure"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM"
      ],
      "metadata": {
        "id": "LXMhyoM3Wnq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mkzNZxxdhsa5"
      },
      "outputs": [],
      "source": [
        "class SVM():\n",
        "  def __init__(self,C=1.0):\n",
        "    # C error terms\n",
        "    self.C = C\n",
        "    self.w = 0\n",
        "    self.b = 0\n",
        "\n",
        "  # Hinge Loss Function / Calculation\n",
        "  def hingeloss(self, w, b, x, y):\n",
        "    # Regularizer term\n",
        "    reg = 0.5 * (w * w)\n",
        "\n",
        "    for i in range(x.shape[0]):\n",
        "      # Optimization term\n",
        "      opt_term = y[i] * ((np.dot(w, x[i])) + b)\n",
        "\n",
        "      # calculating loss\n",
        "      loss = reg + self.C * max(0, 1-opt_term)\n",
        "    return loss[0][0]\n",
        "\n",
        "  def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
        "    # The number of features in X\n",
        "    number_of_features = X.shape[1]\n",
        "\n",
        "    # The number of Samples in X\n",
        "    number_of_samples = X.shape[0]\n",
        "\n",
        "    c = self.C\n",
        "\n",
        "    # Creating ids from 0 to number_of_samples - 1\n",
        "    ids = np.arange(number_of_samples)\n",
        "\n",
        "    # Shuffling the samples randomly\n",
        "    np.random.shuffle(ids)\n",
        "\n",
        "    # creating an array of zeros\n",
        "    w = np.zeros((1, number_of_features))\n",
        "    b = 0\n",
        "    losses = []\n",
        "\n",
        "    # Gradient Descent logic\n",
        "    for i in range(epochs):\n",
        "      # Calculating the Hinge Loss\n",
        "      l = self.hingeloss(w, b, X, Y)\n",
        "\n",
        "      # Appending all losses \n",
        "      losses.append(l)\n",
        "      \n",
        "      # Starting from 0 to the number of samples with batch_size as interval\n",
        "      for batch_initial in range(0, number_of_samples, batch_size):\n",
        "        gradw = 0\n",
        "        gradb = 0\n",
        "\n",
        "        for j in range(batch_initial, batch_initial + batch_size):\n",
        "          if j < number_of_samples:\n",
        "            x = ids[j]\n",
        "            ti = Y[x] * (np.dot(w, X[x].T) + b)\n",
        "\n",
        "            if ti > 1:\n",
        "              gradw += 0\n",
        "              gradb += 0\n",
        "            else:\n",
        "              # Calculating the gradients\n",
        "              #w.r.t w \n",
        "              gradw += c * Y[x] * X[x]\n",
        "              # w.r.t b\n",
        "              gradb += c * Y[x]\n",
        "\n",
        "        # Updating weights and bias\n",
        "        w = w - learning_rate * w + learning_rate * gradw\n",
        "        b = b + learning_rate * gradb\n",
        "\n",
        "    self.w = w\n",
        "    self.b = b\n",
        "\n",
        "    return self.w, self.b, losses\n",
        "\n",
        "  def predict(self, X):\n",
        "    prediction = np.dot(X, self.w[0]) + self.b # w.x + b\n",
        "    return np.sign(prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOG"
      ],
      "metadata": {
        "id": "AKFm3J8JWqPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HOG:\n",
        "    def __init__(self, blockSize, cellSize, nbins, sbins):\n",
        "        self.blockSize     = blockSize\n",
        "        self.cellSize      = cellSize\n",
        "        self.nbins         = nbins\n",
        "        self.sbins         = sbins\n",
        "    def __gray(self):\n",
        "        picture = self.picture_array\n",
        "        self.gray = 0.299*picture[:,:,0]+0.587*picture[:,:,1]+0.114*picture[:,:,2]\n",
        "    def __calc_gradient(self):\n",
        "        input_   = self.gray\n",
        "        output_x = np.zeros((self.height,self.width))\n",
        "        output_y = np.zeros((self.height,self.width))\n",
        "\n",
        "        for r in range(self.height):\n",
        "            for c in range(self.width):\n",
        "\n",
        "                for i in range(-1,2):\n",
        "                    pixel_r = r + i\n",
        "                    pixel_r = min(max(0, pixel_r), self.height - 1)\n",
        "                    output_y[r,c] += input_[pixel_r,c] * i\n",
        "\n",
        "                    pixel_c = c + i\n",
        "                    pixel_c = min(max(0, pixel_c), self.width - 1)\n",
        "                    output_x[r,c] += input_[r,pixel_c] * i\n",
        "        return output_x, output_y\n",
        "    def __calc_direc_mag(self):\n",
        "        self.__gray()\n",
        "        gradient_x, gradient_y = self.__calc_gradient()\n",
        "        self.magnitude = np.sqrt(np.square(gradient_x)+np.square(gradient_y))\n",
        "        self.direction = np.mod(np.add(360, np.rad2deg(np.arctan2(np.array(gradient_y), np.array(gradient_x)))), 360)\n",
        "    def __cell_hist(self,idx, idy):\n",
        "        output = np.zeros(9) # output = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "        # duyệt qua kích thước cell theo chiều cao\n",
        "        for r in range(self.cellSize[0]):\n",
        "          # duyệt qua kích thước cell theo chiều rộng\n",
        "            for c in range(self.cellSize[1]):\n",
        "              # cột và dòng hiện tại trong ảnh\n",
        "                cur_r = idy*self.cellSize[0] + r\n",
        "                cur_c = idx*self.cellSize[1] + c\n",
        "                # kiểm tra\n",
        "                if cur_r>=self.height or cur_c >= self.width:\n",
        "                    break\n",
        "\n",
        "                # chia lấy phần nguyên và phần dư\n",
        "                quotient = int(self.direction[cur_r][cur_c]//self.sbins)\n",
        "                remainder = self.direction[cur_r][cur_c] % self.sbins\n",
        "\n",
        "                if remainder==0:\n",
        "                    output[quotient] += self.magnitude[cur_r][cur_c]\n",
        "                else:\n",
        "                    first_bin = quotient\n",
        "\n",
        "                    second_bin = first_bin+1\n",
        "\n",
        "                    output[first_bin] += self.magnitude[cur_r][cur_c]*\\\n",
        "                        ((second_bin*self.sbins - self.direction[cur_r][cur_c])/ \\\n",
        "                                         (second_bin*self.sbins - first_bin*self.sbins))\n",
        "\n",
        "                    second_bin_idx = second_bin\n",
        "                    if second_bin > 8:\n",
        "                        second_bin_idx = 0\n",
        "                    output[second_bin_idx] += self.magnitude[cur_r][cur_c]*\\\n",
        "                        ((self.direction[cur_r][cur_c] - first_bin*self.sbins)/(second_bin*self.sbins - first_bin*self.sbins))\n",
        "        return output\n",
        "\n",
        "    def __all_hist(self):\n",
        "        hist = []\n",
        "        for y in range(0,self.n_cell[0]):\n",
        "            row = []\n",
        "            for x in range(0,self.n_cell[1]):\n",
        "                output = self.__cell_hist(x,y)\n",
        "                row.append(output)\n",
        "            hist.append(row)\n",
        "        self.hist = np.array(hist)\n",
        "\n",
        "        \n",
        "    def compute_HOG(self, picture):\n",
        "        self.picture_array = picture\n",
        "        self.height, self.width, self.channel = self.picture_array.shape\n",
        "        self.n_cell  = (self.height//self.cellSize[0], self.width//self.cellSize[1])\n",
        "        self.n_block = (self.n_cell[0] - self.blockSize[0] + 1, self.n_cell[1] - self.blockSize[1] + 1)\n",
        "        \n",
        "        self.__calc_direc_mag()\n",
        "        self.__all_hist()\n",
        "        norm_array_size = self.n_block[0] * self.n_block[1] * self.blockSize[0] * self.blockSize[1] * self.nbins\n",
        "        l2 = np.empty(self.n_block)\n",
        "        for i in range(self.n_block[0]):\n",
        "            for j in range(self.n_block[1]):\n",
        "                l2[i][j] = math.sqrt(np.sum(np.square(self.hist[i:i+2, j:j+2])))\n",
        "        norm_block = np.zeros((self.n_block[0], self.n_block[1], self.blockSize[0], self.blockSize[1], self.nbins))\n",
        "        for y in range(self.n_block[0]):\n",
        "            for x in range(self.n_block[1]):\n",
        "                out = self.hist[y: y + self.blockSize[0], x: x + self.blockSize[1]] / (l2[y][x] + 1)\n",
        "                norm_block[y][x] = out\n",
        "        self.HOG        = norm_block.flatten()\n",
        "        self.norm_block = norm_block\n",
        "        return self.HOG"
      ],
      "metadata": {
        "id": "6elbwjp4WrPD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Đọc data"
      ],
      "metadata": {
        "id": "igvtzXRlX032"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYGSfLIXNwe2",
        "outputId": "a0cfee6f-2b63-44f7-f173-6e5a8149ee85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cell_size = (8,8)"
      ],
      "metadata": {
        "id": "oSYXaWpQN_J9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cKbrU0kbM0j6"
      },
      "outputs": [],
      "source": [
        "list_cat = glob2.glob('drive/MyDrive/ltssud/data/Cat/**')\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in range(5):\n",
        "    img = Image.open(list_cat[i])\n",
        "    img = img.resize((400,400), Image.LANCZOS)\n",
        "    images.append(np.array(img))\n",
        "    labels.append(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5X7TNxfEM0j7"
      },
      "outputs": [],
      "source": [
        "list_dog = glob2.glob('drive/MyDrive/ltssud/data/Dog/**')\n",
        "\n",
        "for i in range(5):\n",
        "    img = Image.open(list_dog[i])\n",
        "    img = img.resize((400,400), Image.LANCZOS)\n",
        "    images.append(np.array(img))\n",
        "    labels.append(-1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(images)\n",
        "y = np.array(labels)"
      ],
      "metadata": {
        "id": "HWeY3Or8jakZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "oGqEcWO3NQs1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def big_fit(X_train, y_train, hog, svm):\n",
        "  x_train = []\n",
        "  t = 0\n",
        "  for x in X_train:\n",
        "    print(t)\n",
        "    x_train.append(hog.compute_HOG(x))\n",
        "    t+=1\n",
        "  x_train = np.array(x_train)\n",
        "  svm.fit(x_train, y_train)\n",
        "\n",
        "def big_predict(X_test, y_test, hog, svm):\n",
        "  x_test = []\n",
        "  t = 0\n",
        "  for x in X_test:\n",
        "    print(t)\n",
        "    x_test.append(hog.compute_HOG(x))\n",
        "    t+=1\n",
        "  x_test = np.array(x_test)\n",
        "  return svm.predict(x_test)"
      ],
      "metadata": {
        "id": "onBGKDPfQHjG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hog = HOG((2,2), (8,8), 9, 40)\n",
        "# svm = SVM()"
      ],
      "metadata": {
        "id": "X-UiPA4jQ96W"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "TZuzNXO1eKOo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# svm = SVC(kernel='linear', C=1.0) "
      ],
      "metadata": {
        "id": "xFslcBJ7eOkI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from scipy import ndimage\n",
        "from shutil import copyfile\n",
        "from tensorflow.keras.layers import Conv2D,Add,MaxPooling2D, Dense, BatchNormalization,Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator "
      ],
      "metadata": {
        "id": "ZkVTFBsWUQKQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(400,400,3))\n",
        "x =  tf.keras.layers.Conv2D(32, (3,3), activation='relu')(inputs)\n",
        "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
        "\n",
        "x = tf.keras.layers.Conv2D(128, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.Conv2D(256, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D(2,2)(x)\n",
        "\n",
        "\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(1024, activation='relu')(x) \n",
        "x = tf.keras.layers.Dense(2, activation='softmax')(x) \n",
        "\n",
        "model = Model(inputs=inputs, outputs=x)"
      ],
      "metadata": {
        "id": "hMyrDJ5BUPfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "DBB-8fxMUgeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train = tf.keras.layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "PFfaTnHPmFRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_t = np.array([0 if x==-1 else 1 for x in y_train])\n",
        "y_te = np.array([0 if x==-1 else 1 for x in y_test])"
      ],
      "metadata": {
        "id": "b3AV4kESmih-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_t, batch_size = 10,\n",
        "\tepochs=10, verbose=1)"
      ],
      "metadata": {
        "id": "4jrJ8QnSU2Zr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}